---
title: Transformation of Variables
author: JSH
date: 2025-04-15 10:30:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, Regression]
use_math: true
---

# Transformation of Variables

<!-- 변수변환은 모형이 잘 맞도록 하기 위함. y를 변환할수도, x를 변환할 수도 있다. 예를 들면 log값을 취했을 때 설명이 더 잘된다던다.
두번째로는 선형성, 등분산성이 깨지지 않게 한다 -->

## Reasons of transformation
Theoretical consideration
* Example: when $T_i = \alpha \beta^i$ is theoretical model, changing it to $\log T = \log \alpha + i \log \beta + \epsilon_i$
<!-- 원래 theoretical model과 바꾼 모델은 오차 분포 가정이 다르므로 같은 모델이라고 할 수는 없다 -->
<!-- 분포의 오른쪽 꼬리가 긴 경우에는 로그 변환이 많이 쓰인다 -->

Response variables can be related to the mean $var(Y_i) = E(Y_i)$
* Example: Poisson distribution <!-- 로그변환 등 변수변환으로 등분산가정이 깨지는걸 막을 수 있다 -->

There is neither prior theoretical nor probabilistic reasons, but transformation can be useful if residuals do not satisfy the assumptions. 

## Use transformation to achieve "linearity" and/or "homoscedasticity"
c.f.) Heteroscedasticity <!-- 이분산성 -->

### Nonlinear to linear
* $Y = \alpha X^{\beta}$
  * Transformation: $Y' = \log Y, X' = \log X$
  * Linear form: $Y' = \log \alpha + \beta X'$
* $Y = \alpha e^{\beta X}$
  * Transformation: $Y' = \ln Y$
  * Linear form: $Y' = \ln \alpha + \beta X$
* $Y = \alpha + \beta \log X$
  * Transformation: $X' = \log X$
  * Linear form: $Y = \alpha + \beta X'$
* $Y = \frac{X}{\alpha X - \beta}$
  * Transformation: $Y' = \frac{1}{Y}, X' = \frac{1}{X}$
  * Linear form: $Y' = \alpha - \beta X'$
* $Y = \frac{e^{\alpha + \beta X}}{1 + e^{\alpha + \beta X}}$
  * Transformation: $Y' = \ln \frac{Y}{1 - Y}$
  * Linear form: $Y' = \alpha + \beta X$
 
### Heterogeneous variance to Homogenous variance
$(x, y)$ - linear, but $\epsilon \sim (0, v(x) \sigma^2) \Rightarrow (\frac{x}{\sqrt{v(x)}}, \frac{y}{\sqrt{v(x)}})$: linear with homogenous variance.

Then, $Y' = \beta_0 + \beta_1 X' + \epsilon '$

#### Example
For the survival data, it is well known that it follows formula $n_t = n_0 \cdot \exp (\beta_1 t)$ theoretically.

Then, $\log n_t = \log n_0 + \beta_1 t$.
Let $Y' = \log n_t$ and $\beta_0 = \log n_0, Y' = \beta_0 + \beta_1 + \epsilon$, where $\epsilon \sim N(0, \sigma^2)$.
Therefore, $\log n_t \sim N(\beta_0 + \beta_1 t, \sigma^2)$.

<!-- 비선형 회귀에서 n_t = n_0 \cdot \exp (\beta_1 t)를 바로 적합할 수도 있지만 이때는 n_t ~ N(n_0 exp(\beta t), \sigma^2)를 따른다. 오차항의 분포 가정이 전혀 다른 모델이 된다 -->

## Variance stabilization transformation
$Y_i \mid x_i \sim indep N(\mu_i, \sigma_i^2) \rightarrow E(Y_i \mid x_i) = \mu_i$ and $Var(Y_i \mid x_i) = \sigma_i^2$ are independent

However, in reality, distribution of $Y_i \mid x_i$ could not be normal distribution.
Therefore, there are cases where $E(Y_i \mid x_i)$ and $Var(Y_i \mid x_i)$ have functional relationships with each other.
(Binomial distribution, Poisson distribution)

If the distribution of $Y_i \mid x_i$ or the functional relationship between $E(Y_i \mid x_i)$ and $Var(Y_i \mid x_i)$ is known, a special transformation can satisfy the assumption of a normal distribution (approximately) and eliminate the functional relationship.

### Poisson distribution
Probability Distribution of $Y$: Poisson

$Var(Y)$ in terms of its mean $\mu$: $\mu$
* Therefore, $Var(Y_i) = E(Y_i)$

Transformation: $\sqrt{y}$ or $(\sqrt{Y} + \sqrt{Y+1})$

Resulting Variance: 0.25  <!-- 평균과의 관련성이 사라진다 -->
* $g(y) = \sqrt{y}, g'(y) = \frac{1}{2 \sqrt{y}}$
* $var(g(y)) = (\frac{1}{2 \sqrt{y}})^2 \cdot \mu = 0.25$

#### Remark: Dleta method
$Y_i \sim N(\mu, \sigma^2)$

$g(Y_i) \sim N(g(\mu), g'(\mu)^2 \cdot \sigma^2)$

### Binomial distribution
Probability Distribution of $Y$: Binomial

$Var(Y)$ in terms of its mean $\mu$: $\mu(1-\mu)/n$

Transformation: $\sin^{-1} \sqrt{Y}$ for degrees, $\sin^{-1} \sqrt{Y}$ for radians

Resulting Variance: $821/n$ for degrees, $0.25/n$ for radians

### Negative binomial distribution
Probability Distribution of $Y$: Negative binomial

$Var(Y)$ in terms of its mean $\mu$: $\mu + \lambda^2 \mu^2$

Transformation: $\lambda^{-1} \sinh^{-1}(\lambda \sqrt{Y})$ or $\lambda^{-1} \sinh^{-1}(\lambda \sqrt{Y} + 0.5)$

Resulting Variance: 0.25

<!-- 분산 (residual)과 X, X^2, predicted의 scatter plot을 그리는 목적은 var(Y)가 X, X^2, E(Y)에 대한 함수인지 살펴보는 역할을 한다. 각각의 역할 숙지 -->

### Remark
We can fit $Y_i = \beta_0 + \beta_1 x_i + \epsilon_i, var(\epsilon_i) = k^2 x_i^2$ 

$\Rightarrow \frac{y_i}{x_i} = \beta_0 \frac{1}{x_i} + \beta_1 + \epsilon_i ', var(\epsilon_i ') = k^2$

<!-- 이 수식에서 원래 알고 싶었던건 beta1이기 때문에 변환 후에는 상수가 중요해진다 -->

## Power transformation (Box-cox transformation)
$\frac{x^{\lambda} - 1}{\lambda}, \frac{y^{\lambda} - 1}{\lambda}$ for various value of $\lambda$

$\lim_{\lambda \rightarrow 0} \frac{x^{\lambda} - 1}{\lambda} = \log x$

If negative value is included, Box-cox transformation cannot be used. Yeo-Johnson transformation can be used instead.
