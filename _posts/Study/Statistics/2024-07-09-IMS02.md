---
title: Discrete Random variables
author: JSH
date: 2024-07-09 10:01:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, IMS]
use_math: true
---

# Random Variables

## Random Variables 

<!-- 
random variable은 표본공간에 들어가는 원소(element)들을 실수로 대응시켜주는 함수
vs. probability는 표본공간의 부분집합(set)을 실수로 대응시켜주는 함수
-->

### Definition
For sample space $S$, a function $X$, which assigns to $c \in S$ only one number $X(c) = x$

i.e., $X$: random variable $\Leftrightarrow X:S \rightarrow R$

Random variable is defined on the element of sample space

The probability set function, $P$, is defined on the subset of sample space

### Relationship between probability set function and random variable
In our notion, we define that for $A \subset R$

$X^{-1}\\{A\\} \equiv \\{c \in S: X(c) \in A\\}$: make sure that $X^{-1}\\{A\\}$ indicates the inverse image of $A$ <!-- X^-1{A}는 event, 표본공간의 부분집합 -->

$P(X^{-1}\\{A\\}) \equiv P(X \in A) \equiv P_X(A)$

For example, $\\{c \in S: X(c) \leq a\\} = X^{-1}\\{(-\infty, a\]\\}$   <!-- X^-1{a}: 확률변수 X가 a가 되게 하는 sample space의 집합 -->

![image](https://github.com/user-attachments/assets/9f3f2219-0210-4dce-a396-9c79060dc130)


#### Example
When we toss a coin, we are usually interested in the total number of spots on the sides that are "up" are counted.
If we define $X(H) = 1$ and $X(T) = 0$,
$P_X(1) = P(X = 1) = P(X^{-1} \\{1 \\}) = P(\\{c \in S: X(c) = 1 \\}) = P(\\{H \\})$  <!-- 반드시 이 과정을 거쳐서 답을 도출한다는 것을 기억하기 -->

#### Example
When we cast a die,
* We define $X(1) = 1, X(2) = 2, \ldots, X(6) = 6$. then, $P(X \leq 4) = P(X^{-1} \\{(-\infty, 4]\\}) = P(\\{c \in X: X(c) \leq 4 \\}) = P(\\{1, 2, 3, 4 \\})$
* We define $X(c) = 4$ if $C$ is a even number and otherwise $X(c) = 5$. Then, $P(X \leq 4) = P(X^{-1} \\{(-\infty, 4]\\}) = P(\\{c \in S: X(c) \leq 4 \\}) = P(\\{2, 4, 6 \\})$
<!-- 동일한 확률공간이라 하더라도 확률변수를 어떻게 정의하느냐에 따라서 확률이 달라진다 -->

#### Example
(uniform distribution) Let $X$ be the number of upfaces when two coins are cast.
It is known that $P(H) = P(T) = 0.5$.
Then, find $P(X \leq x)$.

$P(X \leq x) = P( \\{c \in S \mid X(c) \leq x \\}), X(c) \in \\{0, 1 ,2 \\}$

* $x < 0: P(X \leq x) = 0$
* $0 \leq x < 1: P(X \leq x) = P(X = 0) = P(\\{TT \\}) = 1/4$
* $1 \leq x < 2: P(X \leq x) = P(X = 0 or 1) = P(\\{TT, TH, HT \\}) = 3/4$
* $x \geq 2: P(X \leq x) = P(X = 0 or 1 or 2) = P(\\{TT, TH, HT, HH \\}) = 1$

#### Two major difficulties in practical situations
* In many practical situations, the probabilities assigned to the events are unknown
  *  Estimate it by using the relative frequency
  *  Under the certain assumptions, we can estimate it (e.g., possion distribution)
  In general, if we know the distribution of $X$, we can estimate the parameter and then we can calculate $P(X < c)$
* There are many ways of defining a random variable $X$ on $S$

<!-- 여기에 정리하지 않은 예제들도 반드시 파악하고 가야 함! -->


### Space of $X$
The set of real number $S_p(X) = \\{x: x = X(c), c \in S \\}$  <!-- sample space에 들어가는 개별 outcome들을 확률변수에 대입시켰을 때 나올 수 있는 값들의 집합 --> 

### Types of random variable
* $X$: discrete r.v. $\Leftrightarrow S_p(X)$: a countable set <!-- 많아봤자 자연수의 집합일 때 -->
* $X$: continuous r.v. $\Leftrightarrow S_p(X)$: an interval of real numbers

c.f.) countable: one-to-one with positive integers

## Probability distribution function

### Probability mass function (pmf)
For $X$: discrete r.v.,

$p_X(x) = \begin{cases}P(X=x) & x \in S_p(X) \\ 0 & \text{o.w.}\end{cases}$

where $S_p(X) = \\{d_1, d_2, \ldots\\}$

For a given probability set function, its probability mass (density) function can be different, depending on definition of a random variable


### Probability density function (pdf)
For $X$: continuous r.v.,

$P(a < X \leq b) = \int_{a}^{b} f_X(t)dt$ for $f_X(t) \geq 0$ on $[a, b]$, where $a$ and $b$ are any real numbers

$f_X(x)$: probability density function of $X$  <!-- pdf는 무수히 많다. 그 중 아무거나 사용하면 됨 -->

#### Support of $X, S(X)$
* $X$: discrete r.v. $\Rightarrow S(X) = \\{x \in R: P_X(x) > 0 \\}$  <!-- discrete일 때는 S_(X) = S(X) --> 
* $X$: continuous r.v. $\Rightarrow S(X) = \\{x \in R: f_X(x) > 0 \\}$  <!-- continuous일 때는 Space는 확률변수에 의해 다 대응 가능, support는 f_X가 양수일 때이기 때문에 의미가 조금 다르다 -->


### Cumulative distribution function (cdf)
$F_X$: cumulative distribution function of $X$ 
$\Leftrightarrow F_X(x) = P(X \leq x) = P(X^{-1}\\{(-\infty, x]\\})$

* When $X$: discrete r.v. and $S(X) = \\{d_1, d_2, \ldots, d_m, \ldots\\}, F_X(x) = \sum_{d_i \leq x} p_X(d_i)$
* When $X$: continuous r.v., $F_X(x) = \int_{-\infty}^{x} f_X(t)dt$

#### Example
$X$: a real number chosen at random between 0 & 1, and it is distance from 0.
Find the cdf of $X$.

$F_X(x) =$
* $x < 0: 0$
* $0 \leq x \leq 1: x$
* $x > 1: 1$

Then, $f_X(x) = 1$ if $0 \leq x \leq 1$ and 0 o.w

<!-- cdf를 구할 때도 경우를 꼭 나누어야 한다 -->

#### Basic properties of cdf
$F(x)$: cdf of $X$,
* If $a < b, F(a) \leq F(b)$, ($F$: non-decreasing function)
* $0 \leq F(x) \leq 1$
* $\lim_{x \rightarrow -\infty}F(x) = 0, \lim_{x \rightarrow \infty}F(x) = 1$
  * $\lim_{x \rightarrow \infty}F(x) = \lim_{x \rightarrow \infty}P(X\leq x) = \lim_{x \rightarrow \infty}P(X^{-1}(-\infty, x]) = \lim_{n \rightarrow \infty}P(A_n)$
  * $A_1 \subset A_2 \subset \ldots = \cup_{n=1}^{\infty} A_n = S$: increasing property
* $\lim_{h \downarrow 0}F(x+h) = F(x)$, ($F$: right continuous)
  * $\lim_{h \downarrow 0}F(x+h) = \lim_{n \rightarrow \infty}F(x+\frac{1}{n}) = \lim_{n \rightarrow \infty}P(X^{-1} (-\infty, x + \frac{1}{n}]) = \lim_{n \rightarrow \infty}P(A_n)$
  * $A_1 \supset A_2 \supset \ldots = \cap_{n=1}^{\infty}A_n$: decreasing property

#### Theorems with respect to cdf
* $X = Y \Rightarrow F_X(x) = F_Y(x)$; however, the converse does not hold
* $P(a < X \leq b) = F_X(b) - F_X(a)$
* $P(X = x) = F_X(x) - F_X(x-)$ where $F_X(x-) = \lim_{t \uparrow x}F_X(t)$
* $X$: continuous r.v. $\Rightarrow f_X(x) = \frac{dx}{d}F_X(x)$ where $F_X(x)$ is differentiable


# Discrete Random Variables

## Properties of pmf
* $0 \leq p_X(x) \leq 1, x \in R$
* $\sum_{x \in R}p_X(x) = 1$
* $P(a \leq X \leq b) = \sum_{a \leq x \leq b}p_X(x)$

### Definition of Expectatoin
$X$: discrete

If $X$ has a pmf $p(x)$ and $\sum_{x}|u(x)|p(x) < \infty, E(u(X)) = \sum_{x}u(x)p(x)$

### Properties of Expectation
* If $c$ is a constant, then $E(c) = c$
* If $c$ is a constant and $u$ is a function, then $E[cu(X)] = c E[u(X)]$
* If $c_1$ and $c_2$ are constants and $u_1$ and $u_2$ are functions, then $E[c_1 u_1(X) + c_2 u_2(X)] = c_1 E[u_1(X)] + c_2 E[u_2(X)]$

### Mean, Variance, standard deviation

#### Definition
* Mean: $\mu = E(X)$
* Variance: $\sigma^2 = Var(X) = E[(X-\mu)^2]$
* Standard deviatoin: $\sigma = sd(X) = \sqrt{\sigma^2}$
* $r$th moment around $b$: $E[(X-b)^r]$

#### Properties
* $Var(X) \geq 0$
* $Var(X) = E(X^2) - E(X)^2$ \\ $(\because) Var(X) = E(X-\mu)^2 = E(X^2 - 2\mu X + \mu^2) = E(X^2) - E(X)^2$
* $Var(aX+b) = a^2 Var(X)$

### Transformation
Space of $Y = g(X)$: $S_p(Y) = \\{g(x): x \in S_p(X) \\}$

#### pdf of $Y = g(X)$
$p_X(x)$: $X$'s pmf,

* When $g(x)$ is one-to-one from $S_p(X)$ to $S_p(Y)$ and pmf of $X$ is $p_X(x)$, the pmf of $Y$ is $p_Y(y) = p_X(g^{-1}(y))$
* When $g(x)$ is not one-to-one, the pmf of $Y$ is $p_Y(y) = \sum_{g(x) = y}p_X(x)$

### Bernoulli distribution

#### Bernoulli experiment
Random experiment of which the outcome can be classified in one of two mutually exclusive and exhaustive ways.

That is, $S$ = {success, failure}

#### Bernoulli trial
To perform a Bernoulli experiment several independent times

#### Bernoulli random variable
A r.v. associated with a Bernoulli trial by defining it as follows: $X(\\{success\\}) = 1, X(\\{failure\\}) = 0$

#### Definition (Bernoulli distribution)
$X \sim Bernoulli(p); P(X=1) = p$

$\Leftrightarrow$ pmf: $p_X(x) = p^x (1-p)^{1-x}, x = 0, 1$

#### Mean
$E(X) = p$
#### Variance
$Var(X) = p(1-p)$


### Binomial distribution
In a sequence of Bernoulli trials, we are often interested in the total number of successes and not in the order of their occurrence

#### Binomial theorem
$(a+b)^n = \sum_{x=0}^n \binom{n}{x} a^x b^{n-x}$, where $\binom{n}{x} = \frac{n!}{x!(n-x)!}$

#### Definition
$X \sim B(n, p)$
$\Leftrightarrow p_X(x) = \binom{n}{x} p^x (1-p)^{1-x}, x = 0, 1, \ldots, n$

#### Mean: $E(X) = np$
#### Variance: $Var(X) = np(1-p)$


### Hypergeometric distribution
The hypergeometric distribution is used to determine the probability of a certain number of "successes" in a series of draws made without replacement from a fixed population.

When a population is large and a random sample size is relatively small, it makes little difference if the sampling is done with or withoug replacement. (Bionomial distribution and hypergeometirc distribution are similar)


### Geometric distribution
In a sequence of Bernoulli trials, we are often interested in the total number of Bernoulli trials needed to get the first success

#### Definition
$X \sim Geo(p); P(X=1) = p$
$\Leftrightarrow$ pmf: $p_X(x) = p(1-p)^{x-1}, x = 1, 2, \ldots$

#### Mean
$E(X) = 1/p$
#### Variance
$Var(X) = \frac{1-p}{p^2}$


### Negative binomial distribution
In a sequence of Bernoulli trials, we are often interested in the total number of Bernoulli trials needed to observe the $r$th success

#### Definition
$X \sim Negbin(r, p)$

$\Leftrightarrow$ pmf: $p_X(x) = \binom{x-1}{r-1}p^r (1-p)^{x-r}, x = r, r+1, r+2, \ldots$

#### Mean
$E(X) = r/p$
#### Variance
$Var(X) = \frac{r(1-p)}{p^2}$

* By Taylor's theorem, $(1-p)^{-r} = \binom{r-1}{r-1} + \binom{r}{r-1} p + \binom{r+1}{r-1} p^2 + \binom{r+2}{r-1} p^3 + \ldots$


### Moment generating function (mgf)

#### $r$th moment: $E(X^r)$
#### Definition of mgf of $X$
Let $X$ be a discrete r.v. such that $E(e^{tX}) < \infty$ for some $h > 0$ and $-h < t < h$.
Then, mgf of $X: M_X(t) = E(e^{tX}) = \sum_{x \in S}e^{tx} p_X(x)$

#### Relationship between mgf and moment ($E(X^m)$)
For any type of random variable $X$,
$E(X^r) = M_X^{(r)}(0), M_X(t) = \sum_{r=0}^{\infty} \frac{E(X^r)}{r!} t^r, |t| < h$ for some $h > 0$, where $M_X(t)$ exists

#### Uniqueness of mgf (it is also true for continuous random variable)
$M_X(t) = M_Y(t)$ for some $h > 0$ and $-h < t < h$

$\Leftrightarrow F_X(z) = F_Y(z) \forall z \in R$

#### mgf of Binomial distribution
$X \sim B(n, p)$

$M_X(t) = (pe^t + 1 - p)^n$


### Poisson distribution

#### Example of Poisson distribution
Some experiments result in counting the number of times particular events occur at given times or with given physical objects

#### We can have an approximate Poisson process with parameter $\lambda$ if the following conditions are satisfied
* The changes occurring in non-overlapping intervals are independent
* The probability of exactly one change occurring in a sufficiently short interval of length $h$ is approximately $\lambda h$
* The probability of two or more changes occurring in a sufficiently short interval is essentially zero

Under these conditions, we assume that the probability of exactly one change in unit interval is $\lambda$.

$P(X=x) = \lim_{n \rightarrow \infty} P(\text{we observe } x \text{changes from } n \text{units with } 1/n \text{length}) = \lim_{n \rightarrow \infty} {}_nC_x (\frac{\lambda}{n})^x (1 - \frac{\lambda}{n})^{n-x} = \frac{\lambda^x e^{-\lambda}}{x!}$

#### Approximation
If $n$ is large and $p$ is small,
$\frac{(np)^x e^{-np}}{x!} \approx {}_nC_x p^x (1-p)^{n-x}$

#### Definition (Poisson distribution)
$X \sim Poisson(m), m > 0 \Leftrightarrow p(x) = \frac{m^x e^{-m}}{x!}, x = 0, 1, 2, \ldots$

* By Maclaurin's Theorem
$e^m = \sum_{x = 0}^{\infty} \frac{m^x}{x!}$

#### mgf
$M(t) = exp(m(e^t - 1)), -\infty < t < \infty$

#### Mean
$E(X) = m$

#### Variance
$Var(X) = m$
