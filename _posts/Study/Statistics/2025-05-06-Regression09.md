---
title: The Problem of Correlated Errors
author: JSH
date: 2025-05-06 10:30:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, Regression]
use_math: true
---

# The Problem of Correlated Errors

## Introduction
<!-- correlation은 유사한 경우거나 위계가 있을 때 주로 존재 -->
<!-- correlation 보정하는 것은 평균을 보정하거나 (공변량) 오차항끼리 유사하다는 것을 이용할 수도 있다. 
오차항끼리 상관성을 모델링을 통해 보정 가능.
먼저 공변량 보정을 해보고, 그래도 오차항끼리 corrleation이 있으면 그때 오차항 상관성을 그대로 넣어서 보정 시도
-->

### Independent assumption in regression model
Error terms not correlated. $Cov(\epsilon_i, \epsilon_j) = 0, i \neq j$

### Autocorrelation
* the correlation when the observations have a natural sequential order
* adjacent residuals tend to be similar in both temporal and spatial dimensions
  * successive residuals in economic time series
  * observations sampled from adjacent experimental plots or areas
* Autocorrelation can occur as a result of missing explanatory variables in which successive values correlate with each other

## The Effect of Autocorrelation of Errors on Regression Analysis

* LSE's efficiency on regression coefficients is poor (unbiased but no minimum variance) <!-- 회귀계수가 불편추정량은 맞다. 그러나 그중에서 minimum variance를 가지지는 않는다. 효율적이지는 x -->
* $\hat{\sigma^2}$ or s.e. of regression coefficient may be underestimated. This means that the significance of the regression coefficient is over-interpreted
  * $\hat{\sigma^2}$ decreases
  * Since estimation of $\beta$ is $\mid \hat{\beta} / \sigma \sqrt{(X^t X)^{-1}} \mid$ , p-value decreases
  * Cannot control Type 1 error 
* The commonly used confidence intervals or significance tests are no longer valid

### Effective sample number (size)
<!-- correlation이 없는 데이터들 기준으로 동일한 분산을 만드는데 필요한 샘플 -->
<!-- Example에서 effective sample size는 3. 관찰된 데이터가 6개, 9개라고 하더라도 -->
the number of independent samples needed to achieve the same level of precision as a given sample

## Two types of the autocorrelation problem

### Type 1: autocorrelation in appearnce
Omission of a variable that should be in the model.
Once this variable is uncovered, the problem is resolved. 

### Type 2: pure autocorrelation
Involving a transformation of the data 

<!-- 가설검정은 항상 type 1 error와 type 2 error의 관점에서 적절한지 판단해야 한다
가설검정을 할 때 type 1 <= alpha, type 2: beta 관점에서 최대한 작아지게 해서 검정함
-->

## How to detect the correlated errors?
<!-- 통계 분석에서는 type 1 error를 잘 컨트롤하는 게 중요한데 사실 쉽지 않다. 그래서 replication study가 중요 -->

* Residual plot (index plot): a particular pattern
* Run test, Durbin-Watson test

## What to do with correlated errors?

### Type 1
Consider another variables if possible

### Type 2
Consider AR model to the error, then reduce to a model with uncorrelated error.

* Two-step <!-- 회귀분석 시간에 배우는 내용. 간단함 -->
* Auto-correlation model <!-- 뉴턴랩슨 등 이용한 발전된 모델. 시간이 좀 더 걸리지만 더욱 적절한 방법임 -->
  * $Y = X \beta + \epsilon, \epsilon \sim MVN(0, \sigma^2 R), R$ = covariance matrix

## Numerical evidences of correlated errors

### Run test
Use signs (+, -) of residuals.

* Run: repeated occurrence of the same sign.
* NR = # of runs.

#### Test statistic
$Z = \frac{NR - E(NR \mid H_0)}{\sqrt{Var(NR \mid H_0)}} = \frac{NR - (\frac{2 n_1 n_2}{n_1 + n_2}) + 1}{\sqrt{\frac{2 n_1 n_2 (2 n_1 n_2 - n_1 - n_2)}{(n_1 + n_2)^2 (n_1 + n_2 -1)}}}$

where $n_1$: # of positive residuals and $n_2$: # of negative residuals.

If $n_1 + n_2 \geq 20, Z \sim N(0, 1)$

#### Probability
If $r$ is even, that is if $r = 2k$ for a posivie integer $k$:
$P(R = 2k) = \frac{2 \binom{n_1 - 1}{k-1} \binom{n_2 - 1}{k-1}}{\binom{n_1 + n_2}{n_1}}$

If $r$ is odd, that is if $r = 2k + 1$ for a posivie integer $k$:
$P(R = 2k + 1) = \frac{\binom{n_1 - 1}{k} \binom{n_2 - 1}{k-1} + \binom{n_2 - 1}{k} \binom{n_1 - 1}{k-1}}{\binom{n_1 + n_2}{n_1}}$

### Durbin-Watson test
<!-- run test: autocorrelation이 있는지 없는지 여부 알려주는 비모수적 방법. DW test는 크기까지 알려주는 모수적 방법 -->
<!-- 여기 전체적으로 설명 잘 이해하지 못했으므로 꼭 다시 듣기 -->

#### Assumption
Use it under the assumption: $\epsilon_t = \rho \epsilon_{t-1} + w_t$ where $w_t \sim iid N(0, \sigma_w^2)$ and $\mid \rho \mid < 1$

Called as Auto Regression model of order 1 (AR(1)) <!-- 하나 차이날 때 -->

Expansion:
$Cov(Y_{t-1}, Y_t) = Cov(\beta_0 + \beta_1 x_{t-1} + \epsilon_{t-1}, \beta_0 + \beta_1 x_{t} + \epsilon_{t}) = Cov(\epsilon_{t-1}, \epsilon_t)$

$= Cov(\epsilon_{t-1}, \rho \epsilon_{t-1} + w_t) = \rho var(\epsilon_{t-1}) + cov(\epsilon_{t-1}, w_t) = \rho var(\epsilon_{t-1})$

Therefore, $Cov(\epsilon_{t-1}, \epsilon_t) = \rho var(\epsilon_{t-1})$.

$Corr(\epsilon_{t-1}, \epsilon_t) = Cov(\epsilon_{t-1}, \epsilon_t) / \sqrt{Var(\epsilon_{t-1}) Var(\epsilon_t)} = \rho Var(\epsilon_{t-1}) / Var(\epsilon_{t-1}) = \rho$

#### Error term
Error term is equivalent to $\epsilon_t = \sum_{j=0}^{\infty} \rho^j w_{t-j}$

* $E(\epsilon_t) = E(\rho \epsilon_{t-1} + wt) = 0$
* $Var(\epsilon_t) = \sum var(\rho^j w_{t-j}) = \sum_j \rho^{2j} var(w_{t-j}) = \sigma_w^2 \sum_{j=0}^{\infty} \rho^{2j} = \sigma_w^2 \frac{1}{1 - \rho^2}$
* $Cov(\epsilon_t, \epsilon_{t+j}) = \rho^{\mid j \mid} \sigma_w^2 \frac{1}{1 - \rho^2}$

#### Durbin-Watson's statistic & estimator of autocorrelation
$d = \frac{\sum_{t=2}^n (e_t - e_{t-1})^2}{\sum_{t=1}^n e_t^2}, \hat{\rho} = \frac{\sum_{t=2}^n e_t e_{t-1}}{\sum_{t=1}^n e_t^2}$
where $e_i: i$-th OLS residual.

$d \approx 2(1 - \hat{\rho}) \leq 4$

* small value of $d$: posivie correlation
* large value of $d$: negative correlation

#### Case 1: $H_0: \rho = 0$ vs $H_1: \rho > 0$
* $d < d_L$: claim positive corr ($H_1$)
* $d > d_U$: retain the indep ($H_0$)
* $d_L \leq d \leq d_U$: inconclusive

#### Case 2: $H_0: \rho = 0$ vs $H_1: \rho < 0$
* $4-d < d_L$: claim negative corr ($H_1$)
* $4-d > d_U$: retain the indep ($H_0$)
* $d_L \leq 4-d \leq d_U$: inconclusive

## Regression under AR(1) model
### Step 1: Get residuals from OLS & compute
Model: $y_i = \beta_0 + \beta_1 x_i + \epsilon_i, \epsilon_i = \rho \epsilon_{i-1} + w_i$

$\hat{\rho} = \sum_{t=2}^n e_t e_{t-1} / \sum_{t=1}^n e_t^2$

### Step 2: Apply OLS to reduced model (Cochrance and Orcutt method)
$(y_t - \rho y_{t-1} = (1 - \rho) \beta_0 + \beta_1 (x_t - \rho x_{t-1}) + (\epsilon_t - \rho \epsilon_{t-1})$
* $\beta_0^* = (1 - \rho) \beta_0$
* $\beta_1^* = \beta_1$
* $x_t^* = x_t - \rho x_{t-1}$
* $w_t = \epsilon_t - \rho \epsilon_{t-1}$

So, we may assume $w_t \sim iid N(0, \sigma^2_w)$.

Apply OLS, then $\hat{\beta_0} = \hat{\beta_0^*}/(1 - \hat{\rho}), \hat{\beta_1} = \hat{\beta_1^*}$

<!-- two step의 단점. step 1에서의 \hat{\rho}의 샘플 사이즈에 따른 산포가 step 2에서 최종적으로 추정하고자 하는 beta에 반영되지 않는 문제가 있다. -->
<!-- 또 하나의 문제는 beta 추정치들 사이의 covariance가 있는데 추정이 되지 않는 문제가 있다. -->
<!-- 단, 계산이 간단하고 빠다는 중요한 장점이 있다 -->

<!-- autocorrelation 값을 확인하고 (양수, 음수), Pr>DW 혹은 Pr<DW 중 해당하는 p-value를 확인하기 -->

* Note: Pr<DW is the p-value for testing positive autocorrelation, and Pr>DW is the p-value for testing negative autocorrelation.
* Remark: The case of $\rho=0$ in the AR(1) model is called white noise (WN).

### Step 3: Transform back & residual plot
$\hat{\beta_0} = \hat{\beta_0^*}/(1 - \hat{\rho}), \hat{\beta_1} = \hat{\beta_1^*}$

<!-- 예시에서 왼쪽: 앞이 +면 뒤도 +인 경향. NR = 5
예시에서 오른쪽: NR = 8 -->

## Autocorrelation and missing variables
Autocorrelation seen in the residuals may also result from model identification.
e.g., variables left out of the model.

An important predictor that can solve autocorrelation can also be found through a plot of residuals vs potential predictor variables.

The method of solving autocorrelation with variable transformation of Type II is recommended to try at the end.

## Example: Housing starts data
Omission of another predictor variable
* Model 1
  * NR = 6
  * $\beta = 0.0714$
* Model 2
  * Additional predictor variable: mortgage money index
  * NR = 13
  * $\beta = 0.0347$
  * $DW > d_u$

<!-- example: model 2에서 DWrk d_U보다 크기 때문에 autocorrelation 해소 -->
<!-- beta값의 차이가 난다. 둘 다 unbiased하지만 model 2가 효율적이 더 신뢰할 만한 값 -->

### Remark
A large value of $R^2$ does not imply that the data have been fitted and explained well.

A significant value of the DW statistic should be as an indication that a problem exists, and both the possibility of a missing variable or the presence of autocorrelation should be considered.

## Ski Sales Data
DW is not significant.
However, residual shows quarterly pattern.

DW statistic is only sensitive to correlated errors when the correlation occurs between adjacent observations.

<!-- 데이터가 쿼터별로 갈리는 경향이 있다. 1, 4가 유사하고 2, 3이 유사 바로 이전 시점이 아니라 두~세개 떨어져서 correlation 있는 경향임.. -->

Then, extended model by defining the seasonal effect.

### Remark
If the observations are not ordered in time, DW statistic is not strictly relevant.

However, it is a useful diagnostic tool.
