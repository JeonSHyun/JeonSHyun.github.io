---
title: Probability
author: JSH
date: 2024-07-04 10:01:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, IMS]
use_math: true
---

# Probability

<!-- 
확률 계산을 해야 하는 이유: 평균 비교가 명확한 경우도 존재하지만 분산(variance)가 데이터마다 달라서 명확하게 의사결정을 하기 어려운 경우도 존재한다.
따라서, 
통계적 추론 (확률적 추론): 그룹간 비교 시 산포(분산)를 고려한 비교를 한다. 분산 대비 추론을 하는 것이 통계적 추론
-->

## Basic Concepts

### Definition
* Outcome: the result from each experiment
* Random experiment: experiment that can be repeated under the same conditions
* Sample (outcome) space: collection of every possible outcome, denoted by $S$


### Probability (traditional definition)

#### Event
Event is subset of sample space $S$

event $A$ has occurred $\Leftrightarrow$ outcome of the experiment is in $A$

Let $A$ be a part of collection of outcomes in $S$; that is, $A \subset S$. When the random experiment is performed and the outcome of the experiment is in $A$, we say that event $A$ has occurred.

#### Relateive frequency (RF)
In $n$ repetitions of the random experiment, "relative frequency of the event $A$" = $N(A)/n$, where $N(A)$ is the number of times that the event $A$ actually occurred.

As $n$ increases, $N(A)/n \rightarrow p$

In future performances of the experiment, the RF of the event $A$ will either equal or approximate $p$

The $p$ is called the probability that the outcome of the random experiment is in $A$ and denoted by $P(A)$


## Properties of Probability

### Properties of set

#### Subset
Denoted by $C_1 \subset C_2$

if $c \in C2$ for $\forall c \in C_1$

if $C_1 \subset C_2$ and $C_2 \subset C_1 \Leftrightarrow C_1 = C_2$

#### Null set
$C$ is null set if a set $C$ has no elements $\Leftrightarrow C = \emptyset$

#### Union of sets
$C_1 \cup C_2 = \\{x : x \in C_1 \text{or} x \in C_2\\}$

$C_1 \cup C_2 \cup \ldots \cup C_k = \\{x : x \in C_1 \text{or} x \in C_2 \text{or} \ldots \text{or} x \in C_k\\} = \cup_{i=1}^k C_i$

$C_1 \cup C_2 \cup \ldots = \\{x : x \in C_i \text{for some} i\\} = \cup_{i=1}^\infty C_i$

#### Intersection of sets
$C_1 \cap C_2 = \\{x : x \in C_1 \text{and} x \in C_2\\}$

$C_1 \cap C_2 \cap \ldots \cap C_k = \\{x : x \in C_1, x \in C_2, \ldots , x \in C_k\\} = \cap_{i=1}^k C_i$

#### Elementary algebra of sets
* $C_1 \subset C_2 \Rightarrow C_1 \cup C_2, C_1 \cap C_2 = C_1$
* $C_2 = \emptyset \Rightarrow C_1 \cup C_2 = C_1, C_1 \cap C_2 = \emptyset$
* $C \cup C = C, C \cap C = C$

#### Complement
$C^C = \{x : x \notin C, x \in S\}$ where $S$: space

Note: $S^C = \emptyset$

#### Properties of complement
* $C \cup C^C = S, C \cap C^C = \emptyset$
* $C \cup S = S, C \cap S = C$
* $(C^C)^C = C$

#### Mutually exclusive events
$C_1, C_2, \ldots, C_k$ are mutually exclusive events if $C_i \cup C_j = \emptyset$ for $i \neq j$

#### Exhaustive events
$C_1, C_2, ..., C_k$ are exclusive events if $C_1 \cup ... \cup C_k = S$

#### DeMorgan's Laws
Suppose $S$ : space and $C_i \subset S$ ($i$ = 1, 2), $(C_1 \cap C_2)^C = C_1^C \cup C_2^C, (C_1 \cup C_2)^C = C_1^C \cap C_2^C$


### Definition of Probability

#### Set function
A function that assigns real value to each event (set). 
For instance, if we define $f(A)$ indicates the number of the elements in the set $A$, $f(A)$ is a set function.

#### $\sigma$-field
Let $B$ be a collection of subset of $S$. We say is a $\sigma$-field if
* $\emptyset \in B$
* If $C \in B$, then $C^C \in B$
* If $C_1, C_2, \ldots \in B$, then $\cup_{i=1}^{\infty} \in B$

#### Probability set function (Advanced definition of Probability)
Suppose $S$: sample space, and $P$: a real valued function defined on $\sigma$-field, $B$.
* $P(C) \geq 0, \forall C \subset S$
* $P(S) = 1$
* (Countable Additivity) If $C_i \cap C_j = \emptyset$ for $\forall i \neq j, P(\cup_{i=1}^{\infty} C_i) = \sum_{i=1}^{\infty} P(C_i) = P(C_1) + P(C_2) + \ldots$

It $P$ satisfies the three conditions, $P$ is called a probability (set) function.
The traditional definition of probability is also probability set function because $P(A) = \frac{N(A)}{n} \geq 0, P(S) = \frac{N(S)}{n} = \frac{n}{n} = 1$ and $P(A \cup B) = \frac{N(A \cup B}{n} = \frac{N(A) + N(B)}{n} = P(A) + P(B)$ for mutally exclusive event $A$ and $B$.

#### Rules of Probability
* $P(C^C) = 1 - P(C)$
* $P(\emptyset) = 0$
* $C_1 \subset C_2 \Rightarrow P(C_1) \leq P(C_2)$
* $0 \leq P(C) \leq 1$
* $P(C_1 \cup C_2) = P(C_1) + P(C_2) - P(C_1 \cap C_2)$
* Suppose $C_1 \subset C_2 \subset C_3 \subset \ldots$. Then we have $\lim_{n \rightarrow \infty}P(C_n) = P(\cup_{n=1}^{\infty} C_n)$
* Suppose $C_1 \supset C_2 \supset C_3 \supset \ldots$. Then we have $\lim_{n \rightarrow \infty}P(C_n) = P(\cap_{n=1}^{\infty} C_n)$
* $P(\cup_{n=1}^{\infty} \leq \sum_{i=1}^{\infty}P(C_n)$


## Methods of Enumeration

### Multiplication principle
Suppose that an experiment $E_1$ had $n_1$ outcomes and for each of these possible outcomes, and experiment $E_2$ has $n_2$ possible outcomes.
Then composite experiment $E_1 E_2$ that consists of performing first $E_1$ and then $E_2$ has $n_1 n_2$ possible outcomes

### Permutation
Each of the arrangements of $n$ different objects is called a permutation of the $n$ object

### Sampling with replacement
It occurs when an object is selected and then replaced before the next object is selected

### Sampling without replacement
It occurs when an object is not replaced after it has been selected

* If only $r$ positions are to be filled with objects selected from $n$ different objects, then the number of possible ordered arrangements is ${}_nP_k = n(n-1)(n-2) \ldots (n-r+1)$
* The number of ways in whicn $r$ objects can be selected without replacements from $n$ objects when the order of selection is disregarded is ${}_nC_k = \frac{n!}{r!(n-r)!}$

### Distinguishable permutation
Each of the ${}_nC_k$ permutations of $n$ objects, $r$ of one type and $n-r$ of another type
* $(a+b)^n = \sum_{r=0}^n \frac{n!}{r!(n-r)!} b^r a^{n-r}$
* $(a_1 + a_2 + \ldots + a_s)^n = \sum_{n_1 + n_2 + \ldots + n_s = n} \frac{n!}{n_1! n_2! \ldots n_s!}a_1^{n_1} a_2^{n_2} \ldots a_s^{n_s}$
* $\binom{n}{r} = \frac{n!}{r!(n-r)!}$ and $\binom{n}{n_1, n_2, \ldots n_s} = \frac{n!}{n_1! n_2! \ldots n_s!}$


## Conditional Probability

### Conditional probability
The conditional probability of the event $C_2$, given the event $C_1$, $P(C_2|C_1) = \frac{P(C_1 \cap C_2)}{P(C_1)}$ provided $P(C_1) > 0$

### Multiplicatoin rule
$P(C_1 \cap C_2) = P(C_1)P(C_2|C_1)$

$P(C_1 \cap C_2 \cap C_3) = P(C_1)P(C_2|C_1)P(C_3|C_1 \cap C_2)$

### Partition
$C_1, C_2, \ldots, C_k$: partition of $C$ $\Leftrightarrow$ $C_i$'s are mutually exclusive and $\cup_{i=1}^{k}C_i = C$

### Law of total probability
If $C_1, C_2, \ldots, C_k$: partition of $S$, and $P(C_i) > 0 (i = 1, 2, \ldots, k), P(C) = \sum_{i=1}^k P(C_i)P(C|C_i)$.

Here, $P(C_i)$ is called prior probability, and $P(C_i|C)$ posterior probability.


## Independence

### Independence of two events
Two events, $C_1, C_2$ are called independent if and only if $P(C_1 \cap C_2) = P(C_1)P(C_2)$.
Otherwise they are called dependent events.

$C_1, C_2$: independent 

$\Leftrightarrow P(C_1|C_2) = P(C_1)$ when $P(C_2)>0$

$\Leftrightarrow P(C_2|C_1) = P(C_2)$ when $P(C_1)>0$

$\Leftrightarrow C_1^C, C_2$: independent

$\Leftrightarrow C_1, C_2^C$: independent


### Independence of many events

#### Pairwise independence
$C_1, C_2, \ldots, C_n$: pairwise independence $\Leftrightarrow P(C_i \cap C_j) = P(C_i)P(C_j), i \neq j$

#### Mutual independence
$C_1, C_2, \ldots, C_n$: mutually independent

* $P(C_i \cap C_j) = P(C_i)P(C_j), 1 \leq i < j \leq n$
* $P(C_i \cap C_j \cap C_k) = P(C_i)P(C_j)P(C_k), 1 \leq i < j < k \leq n$
* $P(C_1 \cap C_2 \cap \ldots \cap C_n) = P(C_1)P(C_2) \ldots P(C_n)$

#### Independent experiment
A sequence of experiments in such a way that the events associated with one of them are independent of the events associated with the others.

e.g., independent flips of a coin, independent casts of a die


## Bayes's theorem
If $C_1, C_2, \ldots, C_k$: partitoin of $S$, and $P(C_i)>0 (i = 1, 2, \ldots, k), P(C_j|C) = \frac{P(C \cap C_j)}{P(C)} = \frac{P(C_j)P(C|C_j)}{\sum_{i=1}^{k} P(C_i)P(C|C_i)}$
