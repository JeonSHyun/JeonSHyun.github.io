---
title: Probability
author: JSH
date: 2024-07-04 10:01:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, IMS]
use_math: true
---

# Probability

<!-- 
확률 계산을 해야 하는 이유: 평균 비교가 명확한 경우도 존재하지만 분산(variance)가 데이터마다 달라서 명확하게 의사결정을 하기 어려운 경우도 존재한다.
따라서, 
통계적 추론 (확률적 추론): 그룹간 비교 시 산포(분산)를 고려한 비교를 한다. 분산 대비 추론을 하는 것이 통계적 추론
-->

## Basic Concepts

### Definition
* Outcome: the result from each experiment
* Random experiment: experiment that can be repeated under the same conditions
* Sample (outcome) space: collection of every possible outcome, denoted by $S$


### Probability (traditional definition)

#### Event
Event is subset of sample space $S$

event $A$ has occurred $\Leftrightarrow$ outcome of the experiment is in $A$

Let $A$ be a part of collection of outcomes in $S$; that is, $A \subset S$. When the random experiment is performed and the outcome of the experiment is in $A$, we say that event $A$ has occurred.

#### Relateive frequency (RF)
In $n$ repetitions of the random experiment, "relative frequency of the event $A$" = $N(A)/n$, where $N(A)$ is the number of times that the event $A$ actually occurred.

* As $n$ increases, $N(A)/n \rightarrow p$
* In future performances of the experiment, the RF of the event $A$ will either equal or approximate $p$
* The $p$ is called the probability that the outcome of the random experiment is in $A$ and denoted by $P(A)$
  * $P(A) = \lim_{n \rightarrow \infty} \frac{N(A)}{n}$

<!--
A: Set
P: Set -> 실수 (0~1)
따라서 P를 Set function이라고 한다. Set을 넣으면 실수로 보내준다.
-->

## Properties of Probability

### Properties of set

#### Subset ($C_1 \subset C_2$)
if $c \in C2$ for $\forall c \in C_1$

if $C_1 \subset C_2$ and $C_2 \subset C_1 \Leftrightarrow C_1 = C_2$

#### Null set
$C$ is null set if a set $C$ has no elements $\Leftrightarrow C = \emptyset$

#### Union of sets
$C_1 \cup C_2 = \\{x : x \in C_1$ or $x \in C_2\\}$

$C_1 \cup C_2 \cup \ldots \cup C_k = \\{x : x \in C_1$ or $x \in C_2$ or $\ldots$ or $x \in C_k\\} = \cup_{i=1}^k C_i$

$C_1 \cup C_2 \cup \ldots = \\{x : x \in C_i$ for some $i\\} = \cup_{i=1}^\infty C_i$
<!-- i는 C1, C2, ... 어디에 들어가도 괜찮다. 따라서 some(어떤) 이라는 표현 사용 -->

* Remark: $C_1 \subset C_2 \subset \ldots \subset$: increasing property


#### Intersection of sets
$C_1 \cap C_2 = \\{x : x \in C_1 \text{and} x \in C_2\\}$

$C_1 \cap C_2 \cap \ldots \cap C_k = \\{x : x \in C_1, x \in C_2, \ldots , x \in C_k\\} = \cap_{i=1}^k C_i$

$C_1 \cap C_2 \cap \ldots = \\{x : x \in C_i$ for all $i\\} = \cap_{i = 1}^{\infty} C_i$
<!-- all = any -->

* Remark: $C_1 \supset C_2 \supset \ldots \supset$: decreasing property

#### Elementary algebra of sets
* $C_1 \subset C_2 \Rightarrow C_1 \cup C_2 = C_2, C_1 \cap C_2 = C_1$
* $C_2 = \emptyset \Rightarrow C_1 \cup C_2 = C_1, C_1 \cap C_2 = \emptyset$
* $C \cup C = C, C \cap C = C$
<!-- 이부분 증명은 벤다이어그램으로 할 수 있다. 엄밀하게는 부분집합의 정의, 집합이 같다는것의 의미, 교집합과 합집합의 의미 활용 -->

#### Complement
$C^C = \{x : x \notin C, x \in S\}$ where $S$: space

Note: $S^C = \emptyset$

#### Properties of complement
* $C \cup C^C = S, C \cap C^C = \emptyset$
* $C \cup S = S, C \cap S = C$
* $(C^C)^C = C$

#### Mutually exclusive events
$C_1, C_2, \ldots, C_k$ are mutually exclusive events if $C_i \cup C_j = \emptyset$ for $i \neq j$

#### Exhaustive events
$C_1, C_2, ..., C_k$ are exclusive events if $C_1 \cup ... \cup C_k = S$

#### Sample space's partition
$C_1, C_2, \ldots, C_k$ are mutually exclusive and exclusive events

#### DeMorgan's Laws
Suppose $S$ : space and $C_i \subset S$ ($i$ = 1, 2), $(C_1 \cap C_2)^C = C_1^C \cup C_2^C, (C_1 \cup C_2)^C = C_1^C \cap C_2^C$

* Algebra of $(C_1 \cap C_2)^C = C_1^C \cup C_2^C$
  * $(C_1 \cap C_2)^C \subset C_1^C \cup C_2^C$
  * $(C_1^C \cup C_2^C \subset (C_1 \cap C_2)^C$
<!-- 솔루션 참고 -->


### Definition of Probability

#### Set function
A function that assigns real value to each event (set). 
For instance, if we define $f(A)$ indicates the number of the elements in the set $A$, $f(A)$ is a set function.

#### $\sigma$-field
Let $B$ be a collection of subset of $S$. We say is a $\sigma$-field if
* $\emptyset \in B$    <!-- 공집합의 확률은 0 이므로 sigma field에 무조건 들어가야 한다 -->
* If $C \in B$, then $C^C \in B$
  * $P(C^C) = 1 - P(C)$
  * $\emptyset^C = S \in B, P(S) = 1$
* If $C_1, C_2, \ldots \in B$, then $\cup_{i=1}^{\infty} C_i \in B$

<!-- 
sigma field는 확률을 계산할 수 있는 event(집합)들의 집합.
확률공간을 얘기할 때 반드시 S (전체공간), P (확률의 정의), sigma-field를 함께 얘기해야한다
-->

For any event $C$, $B = \\{C, C^C, \emptyset, S \\}$ is a $\sigma$-field

#### Probability set function (Advanced definition of Probability)
Suppose $S$: sample space, and $P$: a real valued function defined on $\sigma$-field, $B$.
* $P(C) \geq 0, \forall C \subset S$
* $P(S) = 1$
* (Countable Additivity) If $C_i \cap C_j = \emptyset$ for $\forall i \neq j, P(\cup_{i=1}^{\infty} C_i) = \sum_{i=1}^{\infty} P(C_i) = P(C_1) + P(C_2) + \ldots$

It $P$ satisfies the three conditions, $P$ is called a probability (set) function.
The traditional definition of probability is also probability set function because $P(A) = \frac{N(A)}{n} \geq 0, P(S) = \frac{N(S)}{n} = \frac{n}{n} = 1$ and $P(A \cup B) = \frac{N(A \cup B}{n} = \frac{N(A) + N(B)}{n} = P(A) + P(B)$ for mutally exclusive event $A$ and $B$.

#### Rules of Probability (and its proof using probability set function)
* $P(C^C) = 1 - P(C)$
  * $C^C \cup C = S$
  * $C$ and $C^C$ is mutually exclusive
  * $P(C^C \cup C) = P(C^C) + P(C) = P(S) = 1$
* $P(\emptyset) = 0$
  *  $S \cup \emptyset = S$
  *  $S \cap \emptyset - \emptyset$
  *  $P(S) = 1 = P(S \cup \emptyset) = P(S) + P(\emptyset) = 1 + P(\emptyset)$
* $C_1 \subset C_2 \Rightarrow P(C_1) \leq P(C_2)$
  * $C_1 \cap (C_1^C \cap C_2) = \emptyset$
  * $C_1 \cup (C_1^C \cap C_2) = C_2$
  * $P(C_2) = P(C_1 \cup (C_1^C \cap C_2)) = P(C_1) + P(C_1^C \cap C_2) \leq P(C_1)$
* $0 \leq P(C) \leq 1$
  * $\emptyset \subset C \subset S$
  * $P(C) \geq 0$
  * $P(C) \leq P(S) = 1$
* $P(\cup_{k =1}^n C_k) = \sum_{k = 1}^n P(C_k) - \sum_{k_1, k_2 \in \\{1, \ldots, n \\}, k_1 < k_2} P(C_{k_1} \cap C_{k_2}) + \ldots + (-1)^{n-1} \sum_{k_1, \ldots, k_n \in \\{1, \ldots, n \\}, k_1 < \ldots < k_n} P(C_{k_1} \cap \ldots \cap C_{k_n})$
  * $P(C_1 \cup C_2) = P(C_1) + P(C_2) - P(C_1 \cap C_2)$
    * $C_1 \cap (C_1^C \cap C_2) = \emptyset$
    * $C_1 \cup (C_1^C \cap C_2) = C_1 \cup C_2$
    * $P(C_1 \cup C_2) = P(C_1 \cup (C_1^C \cap C_2)) = P(C_1) + P(C_1^C \cap C_2)$
    * $(C_1 \cap C_2) \cup (C_1^C \cap C_2) = C_2$
    * $(C_1 \cap C_2) \cap (C_1^C \cap C_2) = \emptyset$
    * $P(C_2) = P(C_1 \cap C_2) \cup P(C_1^C \cap C_2) = P(C_1 \cap C_2) + P(C_1^C \cap C_2)$
    * $P(C_1 \cup C_2) = P(C_1) + P(C_1^C \cap C_2) = P(C_1) + P(C_2) - P(C_1 \cap C_2)$
  * $P(C_1 \cup C_2 \cup C_3) = P(C_1) + P(C_2) + P(C_3) - P(C_1 \cap C_2) - P(C_2 \cap C_3) - P(C_3 \cap C_1) + P(C_1 \cap C_2 \cap C_3)$
* Suppose $C_1 \subset C_2 \subset C_3 \subset \ldots$. Then we have $\lim_{n \rightarrow \infty}P(C_n) = P(\cup_{n=1}^{\infty} C_n)$
  * $D_k = C_{k-1}^C \cap C_k, D_1 = C_1$
  * $D_k \cup C_{k-1} = C_k$
  * $D_k \cap C_{k-1} = \emptyset$
  * $P(C_k) = P(D_k \cup C_{k-1}) = P(D_k) + P(C_{k-1}), k \geq 2$
  * $P(C_n) - P(C_{n-1}) = P(D_n)$
  * $\ldots$
  * $P(C_2) - P(C_1) = P(D_2)$
  * $P(C_n) - P(C_1) = P(D_n) + \ldots + P(D_2)$
  * $P(C_n) = P(D_n) + \ldots + P(D_2) + P(D_1) = \sum_{k=1}^n P(D_k)$
  * $\lim_{n \rightarrow \infty} P(C_n) = \lim_{n \rightarrow \infty} \sum_{k = 1}^n P(D_k) = \sum_{k = 1}^{\infty} P(D_k) = P(\cup_{k=1}^{\infty} D_k) = P(\cup_{k=1}^{\infty} C_k$
    * $D_1, D_2, \ldots$: mutually exclusive
    * $\cup_{k=1}^{\infty} D_k = \cup_{k=1}^{\infty} C_k. C_n = \cup_{k=1}^n D_k$
* Suppose $C_1 \supset C_2 \supset C_3 \supset \ldots$. Then we have $\lim_{n \rightarrow \infty}P(C_n) = P(\cap_{n=1}^{\infty} C_n)$
* $P(\cup_{n=1}^{\infty} \leq \sum_{i=1}^{\infty}P(C_n)$


## Methods of Enumeration

### Multiplication principle
Suppose that an experiment $E_1$ had $n_1$ outcomes and for each of these possible outcomes, and experiment $E_2$ has $n_2$ possible outcomes.
Then composite experiment $E_1 E_2$ that consists of performing first $E_1$ and then $E_2$ has $n_1 n_2$ possible outcomes

### Permutation
Each of the arrangements of $n$ different objects is called a permutation of the $n$ object

### Sampling with replacement
It occurs when an object is selected and then replaced before the next object is selected

### Sampling without replacement
It occurs when an object is not replaced after it has been selected

#### ${}_nP_k$
If only $r$ positions are to be filled with objects selected from $n$ different objects, then the number of possible ordered arrangements is ${}_nP_k = n(n-1)(n-2) \ldots (n-r+1) = \frac{n!}{(n-r)!} = {}_nC_k \times r!$ <!-- n개 중 r개를 뽑아서 r을 나열하는 개수 -->

#### ${}_nC_k$
* The number of ways in whicn $r$ objects can be selected without replacements from $n$ objects when the order of selection is disregarded is ${}_nC_k = \frac{n!}{r!(n-r)!}$
* Suppose that a set contains $n$ objects of two times: $r$ of one type and $n-r$ of the other type. Then, the number of distinguishable arrangements is also ${}_nC_k$

### Distinguishable permutation
Each of the ${}_nC_k$ permutations of $n$ objects, $r$ of one type and $n-r$ of another type
* $(a+b)^n = \sum_{r=0}^n \frac{n!}{r!(n-r)!} b^r a^{n-r} = \sum_{r=0}^n {}_nC_r b^r a^{n-r}$
* $(a_1 + a_2 + \ldots + a_s)^n = \sum_{n_1 + n_2 + \ldots + n_s = n} \frac{n!}{n_1! n_2! \ldots n_s!}a_1^{n_1} a_2^{n_2} \ldots a_s^{n_s}$
* $\binom{n}{r} = \frac{n!}{r!(n-r)!}$ and $\binom{n}{n_1, n_2, \ldots n_s} = \frac{n!}{n_1! n_2! \ldots n_s!}$

<!--
E1 = 전체 중에서 흰색 공 r개가 들어갈 위치를 뽑는 것 = nCr
E2 = 흰색 공이 들어가는 자리에 흰색 공 배치 = r!
E3 = 흰색 공 배치 후 나머지 자리에 검은색 공 배치 = (n-r)!
그래서 E1E2E3 = nPr (전체를 나열하는 것과 같다)
-->

#### Example
Suppose that in a set of $n$ objects, $n_1$ are similar, $n_2$ are similar, $\ldots, n_s$ are similar, where $n_1 + n_2 + \ldots + n_s = n$.
Then the number of distinguishable permutations of the $n$ objects is $\binom{n}{n_1, n_2, \ldots n_s} = \frac{n!}{n_1! n_2! \ldots n_s!}$
<!-- 이걸 좀더 이해할 수 있으면 좋을것 같은데 -->

## Conditional Probability

### Conditional probability
The conditional probability of the event $C_2$, given the event $C_1$, $P(C_2 \mid C_1) = \frac{P(C_1 \cap C_2)}{P(C_1)}$ provided $P(C_1) > 0$

### Multiplicatoin rule
$P(C_1 \cap C_2) = P(C_1)P(C_2 \mid C_1)$

$P(C_1 \cap C_2 \cap C_3) = P(C_1)P(C_2 \mid C_1)P(C_3 \mid C_1 \cap C_2)$

### Partition
$C_1, C_2, \ldots, C_k$: partition of $C$ $\Leftrightarrow C_i$'s are mutually exclusive and $\cup_{i=1}^k C_i = C$

### Law of total probability
If $C_1, C_2, \ldots, C_k$: partition of $S$, and $P(C_i) > 0 (i = 1, 2, \ldots, k), P(C) = \sum_{i=1}^k P(C_i)P(C \mid C_i)$.

Here, $P(C_i)$ is called prior probability, and $P(C_i \mid C)$ posterior probability.

#### Conditional probability satisfies the axioms for a probability function
* $P(C \mid B) = \frac{P(C \cap B)}{P(B)} \geq 0$
* $P(S \mid B) = \frac{P(S \cap B)}{P(B)} = 1, P(\emptyset \mid B) = 0$
* Countable additivity
  * $A_1, A_2, \ldots$: mutually exclusive
  * $P(A_1 \cup A_2 \cup \ldots \mid B) = \frac{P((\cup_{i=1}^{\infty} A_i) \cap B)}{P(B)}$
  * $P((\cup_{i=1}^{\infty} A_i) \cap B) = P(\cup_{i=1}^{\infty} (A_i \cap B)) = \sum_{i=1}^{\infty} P(A_i \cap B)$
  * $\sum_{i=1}^{\infty} \frac{P(A_i \cap B)}{P(B)} = \sum_{i=1}^{\infty} P(A_i \mid B)$


## Independence

### Independence of two events
Two events, $C_1, C_2$ are called independent if and only if $P(C_1 \cap C_2) = P(C_1)P(C_2)$.
Otherwise they are called dependent events.

$C_1, C_2$: independent 

$\Leftrightarrow P(C_1|C_2) = P(C_1)$ when $P(C_2)>0$

$\Leftrightarrow P(C_2|C_1) = P(C_2)$ when $P(C_1)>0$

$\Leftrightarrow C_1^C, C_2$: independent

$\Leftrightarrow C_1, C_2^C$: independent


### Independence of many events

#### Pairwise independence
$C_1, C_2, \ldots, C_n$: pairwise independence $\Leftrightarrow P(C_i \cap C_j) = P(C_i)P(C_j), i \neq j$

#### Mutual independence
$C_1, C_2, \ldots, C_n$: mutually independent

* $P(C_i \cap C_j) = P(C_i)P(C_j), 1 \leq i < j \leq n$
* $P(C_i \cap C_j \cap C_k) = P(C_i)P(C_j)P(C_k), 1 \leq i < j < k \leq n$
* $P(C_1 \cap C_2 \cap \ldots \cap C_n) = P(C_1)P(C_2) \ldots P(C_n)$

#### Independent experiment
A sequence of experiments in such a way that the events associated with one of them are independent of the events associated with the others.

e.g., independent flips of a coin, independent casts of a die


## Bayes's theorem
If $C_1, C_2, \ldots, C_k$: partitoin of $S$, and $P(C_i)>0 (i = 1, 2, \ldots, k), P(C_j|C) = \frac{P(C \cap C_j)}{P(C)} = \frac{P(C_j)P(C|C_j)}{\sum_{i=1}^{k} P(C_i)P(C|C_i)}$
