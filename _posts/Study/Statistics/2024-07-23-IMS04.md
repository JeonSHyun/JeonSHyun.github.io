---
title: Bivariate Distribution
author: JSH
date: 2024-07-23 10:01:00 +0800
categories: [Study, Statistics]
tags: [Study, Statistics, IMS]
use_math: true
---

# Bivariate Distribution

## Distributions of Two Random Variables

### Random Vector and Space

#### Random Vector
$X = (X_1, X_2)^t$: r. vector $\Leftrightarrow X_1, X_2$: random variable on the sample space $S$

#### Space of r. vector $X$
For a r. vector $X = (X_1, X_2)^t, S_p(X) = \\{(x_1, x_2): x_1 = X_1(c), x_2 = X_2(c), c \in S \\}$

### Joint distribution of r. vector

#### Joint cumulative distribution function
For $\forall (x_1, x_2) \in R^2, F_{X_1, X_2} (x_1, x_2) = P(X_1 \leq x_1, X_2 \leq x_2) = P(\\{c: X_1(c) \leq x_1 \\} \cap \\{c: X_2(c) \leq x_2 \\})$

#### Properties
* $F_{X_1, X_2}(x_1, x_2) - F_{X_1, X_2}(y_1, x_2) + F_{X_1, X_2}(y_1, y_2) = P(y_1 < X_1 \leq x_1, y_2 < X_2 \leq x_2)$
* $\lim_{x_1, x_2 \rightarrow \infty} F(x_1, x_2) = 1$
* $\lim_{x_1, x_2 \rightarrow -\infty} F(x_1, x_2) = 0$

#### Discrete random vector
* $X = (X_1, X_2)^t$: discrete r. vector $\Leftrightarrow S_p(X)$ is finite or countable
* $p_{X_1, X_2}(x_1, x_2)$: joint probability mass function

  $\Leftrightarrow p_{X_1, X_2}(x_1, x_2) = \begin{cases} P(X = x_1, X_2 = x_2), & (x_1, x_2) \in S_p(X) \\ 0, & \text{o.w.} \end{cases}$
* Poperties of joint pmf (pdf)
  * $0 \leq p_{X_1, X_2}(x_1, x_2) \leq 1$
  * $\sum_{x_1, x_2}p_{X_1, X_2}(x_1, x_2) = 1$
  * $P((X_1, X_2) \in B) = \sum_{(x_1, x_2) \in B} p_{X_1, X_2}(x_1, x_2)$
* Marginal pdf: the pmf associated to $X_i$ alone

  $p_{X_1}(x_1) = P(X_1 = x_1) = P(X_1 = x_1, X_2 \in S_p(X_2)) = \sum_{x_2}p_{X_1, X_2}(x_1, x_2)$
* Independence of two random variables

  When $p(x_1, x_2)$: joint pmf of $X_1$ and $X_2$; $p_i (x_i)$: marginal pmf of $X_i$,

  $X_1$ and $X_2$ are independent $\Leftrightarrow p(x_1, x_2) = p_1(x_1) \cdot p_2(x_2)$ for $x_1 \in S_p(X)$ and $x_2 \in S_p(Y)$

* Dependence of two random variables

  $X_1$ and $X_2$ are dependent $\Leftrightarrow X_1$ and $X_2$ are not independent

#### Continuous random vector
* $X = (X_1, X_2)^t$: continuous r. vector $\Leftrightarrow$ its cdf $F_{X_1, X_2}(x_1, x_2)$ is continuous
* $f_{X_1, X_2}(x_1, x_2)$: joint probability density function (joint pdf)

  $P((X_1, X_2) \in B) = \int \int_B f_{X_1, X_2}(x_1, x_2)dx_1 dx_2$
* Properties of joint pdf
  * $f_{X_1, X_2}(x_1, x_2) \geq 0$
  * $\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X_1, X_2}(x_1, x_2)dx_1 dx_2 = 1$
  * $f_{X_1, X_2}(x_1, x_2) = \begin{cases} \frac{\partial^2}{\partial x_1 \partial x_2} F_{X_1, X_2}(x_1, x_2), & (x_1, x_2) \in D \\ 0, & \text{o.w.} \end{cases}$

    Where $D = \\{(x_1, x_2) | \exists \frac{\partial^2}{\partial x_1 \partial x_2}F_{X_1, X_2}(x_1, x_2) \\}$
* Support of $X$: $S_X = \\{(x_1, x_2) | f_{X_1, X_2}(x_1, x_2) > 0, (x_1, x_2) \in S_p(X) \\}$
* Marginal pdf

  For $X = (X_1, X_2)$: continuous, $f_{X_1}(x_1) = \int_{-\infty}^{\infty} f_{X_1, X_2}(x_1, x_2)dx_2$
* When $f(x_1, x_2)$: joint pdf of $X_1$ and $X_2$; $f_i(x_i)$: marginal pdf of $X_i$,

  $X_1$ and $X_2$ are independent $\Leftrightarrow f(x_1, x_2) = f_1(x_1) \cdot f_2(x_2)$
* Dependent of two random variables

  $X_1$ and $X_2$ are dependent $\Leftrightarrow X_1$ and $X_2$ are not independent

#### Remark 1
Calculation of probability by using the marginal pdf
* Discrete: $P(X_1 \in B_1) = \sum_{x_1 \in B}p_{X_1}(x_1)$
* Continuous: $P(X_1 \in B_1) = \int_{B_1}f_{X_1}(x_1)dx_1$

#### Remark 2
$X_1$ and $X_2$ are independet if
* $P((X_1, X_2) \in A) = 0$ where $A = \\{(x_1, x_2): f(x_1, x_2) \neq f_1(x_1) \cdot f_2(x_2) \\}$
* $f(x_1, x_2) = g(x_1)h(x_2)$ where $g(x_1), x_1 \in S_{X_1}$ and $h(x_2), x_2 \in S_{X_2}$
