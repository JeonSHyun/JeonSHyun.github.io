---
title: Graph neural networks
author: JSH
date: 2025-12-08 13:03:00 +0800
categories: [Study, Artificial Intelligence]
tags: [Study, Artificial Intelligence, UDL]
use_math: true
---

# Graph neural networks

## What is a graph?
General structure and consists of a set of nodes (or vertices), where pairs of nodes are connected by edges (or links).


## Graph representation
The information at a node is stored in a node embedding.

The information at an edge is stored in an edge embedding.

A graph consists of $N$ nodes connected by $E$ edges, encoded by three matrices $A, X$, and $E$.

### Properties of the adjacency matrix
If raise the adjacency matrix $A$ to the power of $L$, the entry at position $(m, n)$ f $A^L$ contains the number of unique walks of length $L$ from node $n$ t node $m$.


## Graph neural networks, tasks, and loss functions

### Graph neural networks
It takes the node embeddings $X$ and the adjacency matrix $A$ as inputs and passes them through a series of $K$ layers.

Node embeddings are updated at each layer to create intermediate "hidden" representations $H_k$.

### Tasks and loss functions
Graph classification: $Pr(y=1 \mid X, A) = sig[\beta_K + w_K H_K 1/N]$

Node classification: $Pr(y^{(n)} = 1 \mid X, A) = sig[\beta_K + w_K h_K^{(n)}]$
* classify node from node embedding

Edge prediction: $Pr(y^{(mn)} = 1 \mid X, A) = sig[h^{(m)T} h^{(n)}]$
* Predict edge presence from adjacent embeddings

## Graph convolutional networks
Convolution: update each node by aggregating info from nearby nodes

Relational inductive bias:
* $H_1 = F[X, A, \phi_0]$
* $H_2 = F[H_1, A, \phi_1]$
* $H_3 = F[H_2, A, \phi_2]$
* $\ldots$
* $H_K = F[H_{K-1}, A, \phi_{K-1}]$

Parameter sharing: uses the same parameters at every node, reducing the number of parameters and sharing what the network learns at each node across the entire graph.

### Example GCN layer
At each node $n$ in layer $k$, we aggregate information from neighboring nodes by summing their node embeddings.
$agg[n, k] = \sum_{m \in ne[n]} h_k^{(m)}$

* $ne[n]$: set of indices of the neighbors of node $n$.

Hidden layer
* Vertex form: $h_{k+1}^{(n)} = a[\beta_k + \Omega_k \cdot h_k^{(n)} + \Omega_k \cdot agg[n, k]]$
* Matrix form: $H_{k+1} = a[\beta_k 1^T + \Omega_k H_k + \Omega_k H_k A] = a[\beta_k 1^T + \Omega_k H_k (A + I)]$


## Example: graph classification
$H_1 = a[\beta_0 1^T + \Omega_0 X(A+I)]$

$H_2 = a[\beta_1 1^T + \Omega_1 H_1 (A+I)]$

$\ldots$

$H_K = a[\beta_{K-1} 1^T + \Omega_{K-1} H_{K-1} (A+I)]$

$f[X, A, \Phi] = sig[\beta_K + w_K H_K 1/N]$

* The network output $f[\ldots]$ is a single value that determines the probability.

## Example: node classification
For the binary node classification task,
$f[X, A, \phi] = sig[\beta_K 1^T + w_K H_K]$,
where the sigmoid function is applied independently to every element of the row vector input.

## Layers for graph convolutional network
So far, we combined messages from adjacent nodes by summing them together with the transformed current node.

Can there be different approaches to both (i) the combination of the current embedding with the aggregated neighbors and (ii) the aggregation process itself?

### Combining current node and neighbors
In GCN layer, we combined the aggregated neighbors $HA$ with the current nodes $H$ by just summing them:
$H_{k+1} = a[\beta_k 1^T + \Omega_k H_k (A+I)]$

In diagonal enhancement, the current node is multiplied by $(1 + \epsilon_k)$:
$H_{k+1} = a[\beta_k 1^T + \Omega_k H_k (A + (1 + \epsilon_k)I)]$

Related (more general) variation applies a different linear transform $\Psi_k$ to the current node.

$H_{k+1} = a[\beta_k 1^T + \Omega_k H_k A + \Psi_k H_k]$

### Residual connections

The aggregated representation from the neighbors is transformed and passed through the activation function before summation or concatenation with the current node:

$H_{k+1} = [a[\beta_k 1^T + \Omega_k H_k A], H_k]^T$


### Mean aggregation
Sometimes itâ€™s better to take the average of the neighbors rather than the sum.
If the embedding information is more important and the structural information less so.

$agg[n] = \frac{1}{\mid ne[n] \mid} \sum_{m \in ne[n]} h_m$

It can be computed neatly in matrix with $N \times N$ degree matrix $D$ with each non-zero element contains the number of neighbors for the asspciated node.

$H_{k+1} = a[\beta_k 1^T + \Omega_k H_k (AD^{-1} + I)]$

### Max pooling aggregation
Alternative operation that is also invariant to permutation is computing the maximum of a set of objects.

$agg[n] = \max_{m \in ne[n]} [h_m]$

* $\max[\cdot]$ returns the element-wise maximum of the vectors $h_m$ that are neighbors to the current node $n$.

### Aggregatino by attention
In graph attention layers, the weights depend on the data at the nodes:
$H_k' = \beta_k 1^T + \Omega_k H_k$

* Similarity: $s_{mn} = a[\Phi_k^T [h_m', h_n']^T]$
  * These variables are stored in an $N \times N$ matrix $S$

$H_{k+1} = a[H_k' \cdot Softmask[S, A+I]]$

* Softmask[\cdot, \cdot]$ computes the attention values by applying softmax operation separately to each column of its first argument $S$, but only after setting values where the second argument $A+I$ is zero to negative infinity.

### Graph attention
The graph attention network combines the two mechanisms; the weights are both computed from the data and based on the adjacency matrix.

Difference between graph attention and self-attention
* The keys, queries, and values are all the same
* The measure of similarity is different
* The attentions are masked so that each node only attends to itself and its neighbors

As in transformers, this system can be extended to use multiple heads that are run in parallel and recombined
