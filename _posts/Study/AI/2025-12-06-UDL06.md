---
title: Convolutional Neural Networks
author: JSH
date: 2025-12-06 12:03:00 +0800
categories: [Study, Artificial Intelligence]
tags: [Study, Artificial Intelligence, UDL]
use_math: true
---

# Convolutional Neural Networks

## Networks for images

Problems with fully-connected networks
* Size
* Nearby pixels statistically related
  * But could permute pixels and relearn and get same results with FC
* Should be stable under transformations
  * Donâ€™t want to re-learn appearance at different parts of image

Convolutional networks
* Parameters only look at local image patches
* Share parameters across image

## Invariance and equivariance

### Invariance
A function $f[x]$ is invariant to a transformation $t$ if $f[t[x]] = f[x]$.
The function output is the same even after the transformation is applied.

e.g., Image has been translated, but we want our classifier to give the same result

### Equivariance
A function $f[x]$ is equivariant to a transformation $t$ if $f[t[x]] = t[f[x]]$.
The output is transformed in the same way as the input.

e.g., Image has been translated and we want segmentation to translate with it.


## 1D convolution

### Convolution in 1D
Input vector $x = [x_1, x_2, \ldots, x_I]$

Output is weighted sum of neighbors: $z_i = w_1 x_{i-1} + w_2 x_i + w_3 x_{i+1}$

Convolutional kernel or filter (kernel size = 3): $w = [w_1, w_2, w_3]^T$

* Zero padding: Treat positions that are beyond end of the input as zero.
* Stride: shift by $k$ positions for each output
  * Decreases size of output relative to input
* Kernel size: weight a different number of inputs for each output
  * Combine information from a larger area
  * But kernel size 5 uses 5 parameters
* Dilated convolutions: intersperse kernel values with zeros
  *  Combine information from a larger area
  *  Fewer parameters


## Convolutional layers
Convolutional network:
$h_i = a[\beta + w_1 x_{i-1} + w_2 x_i + w_3 x_{i+1}] = a[\beta + \sum_{j=1}^3 w_j x_{i+j-2}]$
* 3 weights, 1 bias

c.f., Fully connected network:
$h_i = a[\beta_i + \sum_{j=1}^D w_{ij} x_j]$
* $D^2$ weights, $D$ biases

## Channels
The convolutional operation averages together the inputs.
And plus passes through ReLU function.
It has to lose information.

Solution:
* Apply several convolutions and stack them in channels
* Sometimes also called feature maps

### Number of parameters
If there are $C_i$ input channels and kernel size $K$,
$\Omega \in R^{C_i \times K}$, $\beta \in R$

If there are $C_i$ input channels and $C_0$ output channels,
$\Omega \in R^{C_i \times C_0 \times K}, \beta \in R^{C_0}$

## Convolutional network for MNIST 1D
CNN has better performance than fully connected network with exactly same number of layers and hidden units.
Fully connected network has larger parameters.

This is because, CNN
* Has better inductive bias
* Forced the network to process each location similarly
* Shares information across locations
* Search through a smaller family of input/ouput mappings, all of which are plausible

## 2D Convolution
Convolution in 2D
* Weighted sum over a $K \times K$ region
* $K \times K$ weights

Build into a convolutional layer by adding bias and passing through activation function
* $h_{i, j} = a[\beta + \sum_{m=1}^3 \sum_{n=1}^3 w_{m, n} x_{i+m-2, j+n-2}]$

### Number of parameters
If there are $C_i$ input channels and kernel size $K \times K$,
$w \in R^{C_i \times K \times K}$, $\beta \in R$

If there are $C_i$ input channels and $C_0$ output channels,
$w \in R^{C_i \times C_0 \times K \times K}, \beta \in R^{C_0}$


## Downsampling and upsampling, $1 \times 1$ convolution

### Downsampling
* Sampling every other position (equivalent to stride two)
* Max pooling (partial invariance to translation)
* Mean pooling

### Upsampling
* Duplicate
* Max-upsampling
* Bilinear interpolation

Upsampling transposed convolutions.

### $1 \times 1$ convolution
* Mixes channels
* Can change number of channels
* Equivalent to running same fully connected network at each position

## Image classification

* Data augmentation
  * Spatial transformations
  * Modifications of the input intensities
* Dropout

## Object detection
Goal: identify and localize multiple objects within the image

## Sementic segmentation
Goal: assign a label to each pixel according to the object that it belongs to (or no label if that pixel does not correspond to anything in the training data)
