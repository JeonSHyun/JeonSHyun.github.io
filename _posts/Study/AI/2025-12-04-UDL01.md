---
title: Shallow Neural Network
author: JSH
date: 2025-12-04 10:03:00 +0800
categories: [Study, AI]
tags: [Study, AI, UDL]
use_math: true
---

# Shallow Neural Network

1D regression model is obviously limited.
I want to be able to describe input/output that are not lines.
I want multiple inputs and outputs.

Shallow neural networks:
* Flexible enough to describe arbitrarily complex input/output mappings
* Can have as many inputs as we want
* Can have as many outputs as we want

## Example network, 1 input, 1 output
1D Linear Regression: $y = f(x, \phi) = \phi_0 + \phi_1 x$

Example shallow network: $y = f(x, \phi) = \phi_0 + \phi_1 a(\theta_{10} + \theta_{11} x) + \phi_2 a(\theta_{20} + \theta_{21} x) + \phi_3 a(\theta_{30} + \theta_{31} x)$
* 10 parameters: $\phi = \\{\phi_0, \phi_1, \phi_2, \phi_3, \theta_{10}, \theta_{11}, \theta_{20}, \theta_{21}, \theta_{30}, \theta_{31} \\}$
* It break down into two parts: $y = \phi_0 + \phi_1 h_1 + \phi_2 h_2 + \phi_3 h_3$ where h is hidden unit.

$a$ is activation function.
* $a[z] = ReLu[z] = 0$ if $z < 0$, $z$ if $z \geq 0$
* ReLU = Rectified Linear Unit

$h$ is hidden unit.
* $h_1 = a[\theta_{10} + \theta_{11} x]$
* $h_2 = a[\theta_{20} + \theta_{21} x]$
* $h_3 = a[\theta_{30} + \theta_{31} x]$

Calculating shallow network:
* Compute three linear functions: $\theta_0 + \theta_1 x$
* Pass through ReLU functions (creates hidden units): $h = a[\theta_0 + \theta_1 x]$
* Weight the hidden units: $\phi h$
* Sum the weighted hidden units to create output: $y = \phi_0 + \phi h$

## Universal approximation theorem
With D hidden units: $y = \phi_0 + \sum_{d=1}^D \phi_d a[\theta_{d0} + \theta_{d1} x] = \phi_0 + \sum_{d=1}^D \phi_d h_d$

A formal proof that, with enough hidden units, a shallow neural network can describe any continuous function on a compact subset of $R^D$ to arbitrary precision.

## More than one output
### Two outputs
1 input, 4 hidden units, 2 outputs
* $h_1 = a[\theta_{10} + \theta_{11} x]$
* $h_2 = a[\theta_{20} + \theta_{21} x]$
* $h_3 = a[\theta_{30} + \theta_{31} x]$
* $h_4 = a[\theta_{40} + \theta_{41} x]$
* $y_1 = \phi_{10} + \phi_{11} h_1 + \phi_{12} h_2 + \phi_{13} h_3 \phi_{14} h_4$
* $y_2 = \phi_{20} + \phi_{21} h_1 + \phi_{22} h_2 + \phi_{23} h_3 \phi_{24} h_4$

## More than one input
### Two inputs
2 inputs, 3 hidden units, 1 output
* $h_1 = a[\theta_{10} + \theta_{11} x_1 \theta_{12} x_2]$
* $h_2 = a[\theta_{20} + \theta_{21} x_1 \theta_{22} x_2]$
* $h_3 = a[\theta_{30} + \theta_{31} x_1 \theta_{32} x_2]$
* $y = \phi_{10} + \phi_{11} h_1 + \phi_{12} h_2 + \phi_{13} h_3$

## General case

### Arbitrary inputs, hidden units, outputs
$D_0$ outputs, $D$ hidden units, and $D_i$ inputs: $y_j = \phi_{j0} + \sum_{d=1}^D \phi_{jd} a[\theta_{d0} + \sum_{i=1}^{D_i} \theta_{di} x_i] = \phi_{j0} + \sum_{d=1}^D \phi_{jd} h_d$
